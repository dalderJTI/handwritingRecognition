<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Handwriting Recognition by dalderJTI</title>
    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/github-dark.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js"></script>
    <script src="javascripts/respond.js"></script>
    <!--[if lt IE 9]>
      <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <!--[if lt IE 8]>
    <link rel="stylesheet" href="stylesheets/ie.css">
    <![endif]-->
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

  </head>
  <body>
      <div id="header">
        <nav>
          <li class="fork"><a href="https://github.com/dalderJTI/handwritingRecognition">View On GitHub</a></li>
          <li class="downloads"><a href="https://github.com/dalderJTI/handwritingRecognition/zipball/master">ZIP</a></li>
          <li class="downloads"><a href="https://github.com/dalderJTI/handwritingRecognition/tarball/master">TAR</a></li>
          <li class="title">DOWNLOADS</li>
        </nav>
      </div><!-- end header -->

    <div class="wrapper">

      <section>
        <div id="title">
          <h1>Handwriting Recognition</h1>
          <p>Using Self Organizing Maps to Recognize Written Characters</p>
          <hr>
          <span class="credits left">Project maintained by <a href="https://github.com/dalderJTI">dalderJTI</a></span>
          <span class="credits right">Hosted on GitHub Pages &mdash; Theme by <a href="https://twitter.com/michigangraham">mattgraham</a></span>
        </div>

        <h3>
<a id="introduction" class="anchor" href="#introduction" aria-hidden="true"><span class="octicon octicon-link"></span></a>Introduction</h3>

<p>Handwriting recognition has many useful applications. It can be used as user input for devices, or to decode and interpret pictures of words into editable unicode text. In the application for this project, I am using it as a means of user input as a replacement for the keyboard on Android devices. </p>

<h3>
<a id="description" class="anchor" href="#description" aria-hidden="true"><span class="octicon octicon-link"></span></a>Description</h3>

<p>Typing on a touchscreen isn't always the easiest. Without a physical keyboard, it is easy to hit the wrong keys or lose your hand position. On larger touch screens, when composing anything longer than a text, it may be more a fluid and easy process to write with a stylus rather than use a virtual keyboard. With the recent release of Google's Handwriting Input Engine, I became interested in how handwriting recognition works, and learns written characters based on user input. </p>

<p>I found a project on GitHub called Thulika that I forked and began to learn in order to develop on. This application is developed for the Android devices and uses the touch screen as the writing surface for the input method. It uses a neural network library named Encog which implements many different types and aspects of neural networks. The nueral network chosen for this application was a Self Organizing Map. My goal for this project is to implement a supervised means of error correction in order to help the keyboard recognize written characters in a faster manner than previously.</p>

<p>When writing on the screen, the keyboard takes the image of the written character and translates it to a bitmap image. The black pixels making up the character are used as the data points for the SOM to map to, as described below.</p>

<h3>
<a id="self-organizing-maps" class="anchor" href="#self-organizing-maps" aria-hidden="true"><span class="octicon octicon-link"></span></a>Self Organizing Maps</h3>

<p>(GIF or Video)
Self Organizing Maps or SOMs, are a map of neurons that are thrown at a data plot. They employ competitive and unsupervised learning to predict the desired output. The competitive part means that the closest neuron to the data point on the plot is selected as the "winner" or Best Matching Unit (BMU). This neuron moves toward the data point, pulling its neighbors with it. This is repeated for however many iterations, and each time the map of neurons more closely resembles and represents the data points on the plot. A good step by step description of how they work, as defined below were found  <a href="http://www.ai-junkie.com/ann/som/som2.html">here</a>, along with more information about SOMs and how they work and are used. </p>

<ol>
<li><p>Each node's weights are initialized.</p></li>
<li><p>A vector is chosen at random from the set of training data and presented to the lattice.</p></li>
<li><p>Every node is examined to calculate which one's weights are most like the input vector. The winning node is commonly known as the Best Matching Unit (BMU).</p></li>
<li><p>The radius of the neighbourhood of the BMU is now calculated. This is a value that starts large, typically set to the 'radius' of the lattice,  but diminishes each time-step. Any nodes found within this radius are deemed to be inside the BMU's neighbourhood.</p></li>
<li><p>Each neighbouring node's (the nodes found in step 4) weights are adjusted to make them more like the input vector. The closer a node is to the BMU, the more its weights get altered.</p></li>
<li><p>Repeat step 2 for N iterations.</p></li>
</ol>

<h3>
<a id="supervised-error-correction" class="anchor" href="#supervised-error-correction" aria-hidden="true"><span class="octicon octicon-link"></span></a>Supervised Error Correction</h3>

<p>While SOMs do a pretty good job at predicting the output you want, they could do a little better by providing it training examples to learn from while in the process of doing their regular work. What I am attempting to do is to collect the input characters from the user for a word, and matching the best guesses of what each character might be to any sequence of possible words in a dictionary. When a word is selected, any characters from the written sequence will be affirmed as correct and solidified as a guess, and any characters that were guessed wrong will be considered the training example that the neural network will learn from, to better guesses in the future. This basically describes the <a href="https://en.wikipedia.org/wiki/Viterbi_algorithm">Viterbi algorithm</a>, which is how I am going to accomplish this. </p>
      </section>

    </div>
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->
    
  </body>
</html>
