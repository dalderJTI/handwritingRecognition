{"name":"Character Recognition and Its Uses as Input","tagline":"Applying Machine Learning to Recognize and Train on Written Characters","body":"![Intro Picture](https://raw.githubusercontent.com/dalderJTI/handwritingRecognition/develop/Thulika/ExampleImages/InputOutput.png)\r\n\r\n## Introduction\r\nCharacter recognition has many useful applications. It can be used as user input for devices, or to decode and interpret pictures of words into editable unicode text. In the application for this project, I am using it as a means of user input for the keyboard on Android devices. For this project I have delved into studying concepts that have already been applied and that I would like to apply to improve the functionality of this input method. \r\n\r\n## Description\r\nTyping on a touchscreen isn't always the easiest. Without a physical keyboard, it is easy to hit the wrong keys or lose your hand position. On larger touch screens, when composing anything longer than a text, it may be more a fluid and easy process to write with a stylus rather than use a virtual keyboard. With the recent release of Google's Handwriting Input Engine, I became interested in how handwriting recognition works and learns written characters based on user input. \r\n\r\nI found a project on GitHub called [Thulika](https://github.com/sinujohn/ThulikaIME) that I forked and began to learn in order to develop on. This application is developed for the Android devices and uses the touch screen as the writing surface for the input method. It uses a neural network library named [Encog](https://github.com/encog) which implements many different types and aspects of neural networks. The neural network chosen for this application was a Self Organizing Map. My goal for this project is to implement a supervised means of error correction in order to help the keyboard recognize written characters and learn from its mistakes as it produces words as output instead of single characters.\r\n\r\nThis application works by creating an overlay on top of the android device, which you use as a canvas. When writing on the screen, the keyboard takes the image of the written character and converts it to data. The pixels of this image are used as the data points (a matrix of boolean values) for the SOM to map to, as described below. \r\n\r\n## Self Organizing Maps\r\n\r\nSelf Organizing Maps or SOMs, are a map of neurons that are thrown at a data plot. They employ competitive and unsupervised learning to predict the desired output. The competitive part means that the closest neuron to the data point on the plot is selected as the \"winner\" or Best Matching Unit (BMU). This neuron moves the farthest and closest toward the data point, pulling its neighbors to a lesser degree with it. This is repeated for however many iterations, and each time the map of neurons more closely resembles and represents the data points on the plot. \r\n\r\n![SOM](https://raw.githubusercontent.com/dalderJTI/handwritingRecognition/develop/Thulika/ExampleImages/SOMVisual.png)\r\n\r\nA good step by step description of how they work, as defined below were found [here](http://www.ai-junkie.com/ann/som/som2.html), along with more information about SOMs and how they work. \r\n\r\n1. Each node's weights are initialized.\r\n\r\n2. A vector is chosen at random from the set of training data and presented to the lattice.\r\n\r\n3. Every node is examined to calculate which one's weights are most like the input vector. The winning node is commonly known as the Best Matching Unit (BMU).\r\n\r\n4. The radius of the neighborhood of the BMU is now calculated. This is a value that starts large, typically set to the 'radius' of the lattice,  but diminishes each time-step. Any nodes found within this radius are deemed to be inside the BMU's neighborhood.\r\n\r\n5. Each neighboring node's (the nodes found in step 4) weights are adjusted to make them more like the input vector. The closer a node is to the BMU, the more its weights get altered.\r\n\r\n6. Repeat step 2 for N iterations.\r\n\r\n## Supervised Error Correction\r\n\r\nSOMs themselves do a pretty good job at recognizing characters. Wouldn't it be better if instead of choosing or confirming each individual character after writing it, we could instead save the input and have the application choose a word that best matches it for us upon completion? Using an algorithm similar to the [Viterbi algorithm](https://en.wikipedia.org/wiki/Viterbi_algorithm), this is possible. \r\n\r\nAfter each input character, the application returns a list of its best guesses of what that input might be by using the SOM. This application will save that array and use it later. \r\n\r\n![Letter Prediction](https://raw.githubusercontent.com/dalderJTI/handwritingRecognition/develop/Thulika/ExampleImages/LetterPredictions.png)\r\n\r\nAs we accumulate these predicted character arrays, we store them into another array. When the 'space' button is pressed, signaling that the word is completed, we begin the processing.\r\n\r\n![Prediction Arrays](https://raw.githubusercontent.com/dalderJTI/handwritingRecognition/develop/Thulika/ExampleImages/PredictionArrays.jpg)\r\n\r\nOur prediction arrays are sorted so that the first character in the array is the one that the SOM decided the input was most like. Each consecutive character after is the next best guess to the previous. Since our prediction arrays are sorted in this manner, we can use the index as each prediction's score. According to the example picture above, the predicted letters near the top will have the best scores. Using a dictionary to compare to, we reduce it's entries to ones that are the same length as our input array. We then find sequences of letters that match any word from reduced dictionary list.\r\n\r\n![Letter Selection](https://raw.githubusercontent.com/dalderJTI/handwritingRecognition/develop/Thulika/ExampleImages/LetterSelection.png)\r\n\r\nWe can then combine the scores for each letter in any confirmed matching word sequences and output them as a list to select from, sorted by score.\r\n\r\nWhen a word is selected, we are provided with a possible training example. For our example, the letter sequence of our selected word should match the letters across the tops of the prediction arrays. By passing the data mapping of the input and the confirmed letter it represents back to the SOM, we can provide it the information it needs to adjust for more accurate future predictions. This is called supervised learning. \r\n\r\n## Other Applications\r\n\r\nAside from being used as an input method which may productively replace the virtual keyboard in certain instances, the problem of recognizing text from images has many other applications. With the right processing performed on an image, the brains of this application also has the potential to recognize any text contained within and use it for whatever reason you can think of.","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}